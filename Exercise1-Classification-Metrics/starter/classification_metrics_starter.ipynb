{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "920e0b9f",
   "metadata": {},
   "source": [
    "# Classification Metrics\n",
    "\n",
    "During the course of this notebook, you will calculate several classification metrics for a random forest classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca565c-40c2-4bab-83fc-65a2c47869bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff8e176",
   "metadata": {},
   "source": [
    "## Dataset Setup\n",
    "\n",
    "In the cell below, we use the `make_blobs` utility function ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html)) to automatically generate `X` and `y` data.\n",
    "\n",
    "The `random_state` argument ensures that we will generate the same dataset every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e9c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin by creating a dataset using Sklearn\n",
    "\n",
    "X, y = make_blobs(n_samples=200, n_features=3, shuffle=True, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3db58b-e8e3-4784-ae37-0ac29f364722",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa712418-50cd-4f25-844a-fcb7ea3f873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7d0e47-d09a-4ddc-8d10-d8b7f4a51e2d",
   "metadata": {},
   "source": [
    "Knowledge check: have we created a *binary* classification problem or a *multiclass* classification problem?\n",
    "\n",
    "<details>\n",
    "  <summary>Answer (click to expand)</summary>\n",
    "\n",
    "  Because we have 3 different values in `y`—`0`, `1`, and `2`—this is a **multiclass** classification problem. A binary classification problem would only have 2 different values.\n",
    "  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1150276-b2f7-4989-80ca-c94e1a3869c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters using a scatterplot\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[:,0], X[:,2], alpha=0.75)\n",
    "ax.set_title(\"Visualizing the First and Third Feature\")\n",
    "ax.set_xlabel(\"First Feature\")\n",
    "ax.set_ylabel(\"Third Feature\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9cde00-bc5e-42e7-9749-3a6612b20b17",
   "metadata": {},
   "source": [
    "## Training a Classifier\n",
    "\n",
    "Next, we train a random forest classifier ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)) using our `X` and `y` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da79527",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=1,random_state=111)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04685955-6391-4068-8768-b93c15fecf94",
   "metadata": {},
   "source": [
    "## Your Task: Calculate Classification Metrics\n",
    "\n",
    "Generate predictions, then calculate the following classification metrics:\n",
    "\n",
    "1. Precision ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html))\n",
    "2. Recall ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html))\n",
    "3. F1 Score ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html))\n",
    "\n",
    "Because this is a multiclass problem, you will need to specify an appropriate value for the `average` argument. Review the documentation to help make this selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdce5848-0d67-4ab3-8e16-f9258e309294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get predictions for X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5aaf8-8b5e-42df-b06b-75d7b0c45ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import precision metric\n",
    "\n",
    "\n",
    "# TODO: calculate precision score for predictions\n",
    "# According to the documentation, \"micro\" means \"Calculate metrics globally by counting the total true positives,\n",
    "# false negatives and false positives\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb95e6-67fe-4901-8ae6-b402780f5ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import recall metric\n",
    "\n",
    "\n",
    "# TODO: calculate recall score for predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7e800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import F1 score metric\n",
    "\n",
    "\n",
    "# TODO: calculate F1 score for predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa28eab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
